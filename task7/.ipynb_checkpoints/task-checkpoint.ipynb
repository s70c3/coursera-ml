{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from  sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Получение данных\n",
    "#считываем таблицу с признаками из features.csv\n",
    "X_train = pd.read_csv('features.csv', index_col='match_id')\n",
    "#получаем значения целевой переменной \n",
    "y_train = X_train['radiant_win']\n",
    "#удаляем признаки, связанные с концом матча\n",
    "X_train = X_train.loc[:, :'dire_first_ward_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: bool)\n",
      "Series([], dtype: bool)\n"
     ]
    }
   ],
   "source": [
    "#Смотрим, какие значения имеют пропуски. \n",
    "num = X_train.count()<len(X_train)\n",
    "print(num[num])\n",
    "#заполняем нулями вместо пропусков\n",
    "X_train = X_train.fillna(0)\n",
    "#проверяем, заполнились ли пропуски (на всякий случай). Всё нормально, идём дальше.\n",
    "num = X_train.count()<len(X_train)\n",
    "print(num[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  0:00:44.975650\n",
      "Number of trees:  10  Score:  0.66483292280491\n",
      "Time elapsed:  0:01:46.937544\n",
      "Number of trees:  20  Score:  0.6821140369500348\n",
      "Time elapsed:  0:02:11.405638\n",
      "Number of trees:  30  Score:  0.6896947542059906\n"
     ]
    }
   ],
   "source": [
    "for i in [10,20,30]:\n",
    "    start_time = datetime.datetime.now()\n",
    "    #настраиваем классификатор\n",
    "    clf = GradientBoostingClassifier(n_estimators=i, random_state=1)\n",
    "    #обучаем выборку\n",
    "    clf.fit(X_train,y_train)\n",
    "    #генератор разбиений\n",
    "    generator = KFold(n_splits=5,shuffle=True, random_state=1)\n",
    "    #оцениваем качество\n",
    "    quality = cross_val_score(X=X_train, y=y_train, estimator=clf, cv=generator, scoring='roc_auc')\n",
    "    print('Time elapsed: ', datetime.datetime.now() - start_time)\n",
    "    print('Number of trees: ',i,' Score: ',np.mean(quality))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отчёт по использованию градиентного бустинга\n",
    "1. Какие признаки имеют пропуски среди своих значений? Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)?\n",
    "\n",
    "Согласно выдаче ```X_train.count()<len(X_train) ``` пропуски имеют:\n",
    "\n",
    "```first_blood_time``` ```first_blood_team``` ```first_blood_player1``` ```first_blood_player2``` ```radiant_bottle_time``` ```radiant_courier_time``` ```radiant_flying_courier_time``` ```radiant_first_ward_time```\n",
    "```dire_bottle_time``` ```dire_courier_time``` ```dire_flying_courier_time``` ```dire_first_ward_time```\n",
    "```first_blood_X ``` имеют пропуски, так как событие \"Первая кровь\"- \"First blood\" может наступить не во всех случаях.\n",
    "```radiant_bottle_time```,  ```radiant_courier_time ```, и ```radiant_flying_courier_time``` \n",
    "2. Как называется столбец, содержащий целевую переменную?\n",
    "\n",
    "```radiant_win```\n",
    "3. Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями?  Какое качество при этом получилось?\n",
    "\n",
    "Time elapsed:  0:01:46.595157\n",
    "\n",
    "Number of trees:  30  Score:  0.6892967175166005\n",
    "\n",
    "4. Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? Что бы вы предложили делать, чтобы ускорить его обучение при увеличении количества деревьев?\n",
    "\n",
    "Особого смысла нет, так как при большем количестве деревьев в разы увеличивается время обучения, а качество изменяется незначительно. Чтобы ускорить обучение возможно изменять глубину деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#нормализуем признаки\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7179727586106518\n",
      "Time elapsed:  0:00:16.212449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1917: ChangedBehaviorWarning: The long-standing behavior to use the accuracy score has changed. The scoring parameter is now used. This warning will disappear in version 0.22.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "#обучаем логистическую регрессию\n",
    "#генератор тот же\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "generator = KFold(n_splits=5,shuffle=True, random_state=1)\n",
    "lgr = LogisticRegressionCV(Cs=10, cv=generator, random_state=1, penalty='l2', scoring='roc_auc')\n",
    "lgr.fit(X_train_scaled, y_train)\n",
    "#predict = lgr.predict_proba(X_train_scaled)\n",
    "print(lgr.score(X_train_scaled, y_train))\n",
    "\n",
    "print('Time elapsed: ', datetime.datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#удалим категориальные признаки\n",
    "\n",
    "X_train_cleaned = X_train.drop(labels=['lobby_type','r1_hero','r2_hero','r3_hero','r4_hero','r5_hero',\n",
    "                                      'd1_hero','d2_hero','d3_hero','d4_hero','d5_hero'], axis=1)\n",
    "X_train_cleaned_scaled=scaler.fit_transform(X_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7178321071588762\n",
      "Time elapsed:  0:00:11.085675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1917: ChangedBehaviorWarning: The long-standing behavior to use the accuracy score has changed. The scoring parameter is now used. This warning will disappear in version 0.22.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "#cнова обучаем логистическую регрессию\n",
    "#генератор тот же\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "generator = KFold(n_splits=5,shuffle=True, random_state=1)\n",
    "lgr2 = LogisticRegressionCV(Cs=10, cv=generator, random_state=1, penalty='l2', scoring='roc_auc')\n",
    "lgr2.fit(X_train_cleaned_scaled, y_train)\n",
    "#lgr2.predict_proba(X_train_cleaned_scaled)\n",
    "print(lgr2.score(X_train_cleaned_scaled, y_train))\n",
    "print('Time elapsed: ', datetime.datetime.now() - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 109 110 112]\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "#подсчитаем количество уникальных игроков в выборке\n",
    "heroes = np.unique(X_train[['r1_hero','r2_hero','r3_hero','r4_hero','r5_hero',\n",
    "                                      'd1_hero','d2_hero','d3_hero','d4_hero','d5_hero']].values)\n",
    "\n",
    "print(heroes)\n",
    "print(max(heroes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#формируем мешок слов по героям\n",
    "# N — количество различных героев в выборке\n",
    "X_pick = np.zeros((X_train.shape[0], max(heroes)))\n",
    "for i, match_id in enumerate(X_train.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, X_train.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, X_train.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#склеиваем с новым признаком\n",
    "X_dummies = np.concatenate([X_train_cleaned_scaled, X_pick], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1917: ChangedBehaviorWarning: The long-standing behavior to use the accuracy score has changed. The scoring parameter is now used. This warning will disappear in version 0.22.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7544331359955426\n",
      "Time elapsed:  0:00:59.391888\n"
     ]
    }
   ],
   "source": [
    "#cнова обучаем логистическую регрессию\n",
    "#генератор тот же\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "generator = KFold(n_splits=5,shuffle=True, random_state=1)\n",
    "lgr2 = LogisticRegressionCV(Cs=10, cv=generator, random_state=1, penalty='l2', scoring='roc_auc')\n",
    "lgr2.fit(X_dummies, y_train)\n",
    "#lgr2.predict_proba(X_dummies)\n",
    "print(lgr2.score(X_dummies, y_train))\n",
    "print('Time elapsed: ', datetime.datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестовая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('features_test.csv', index_col='match_id')\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#подсчитаем количество уникальных игроков в выборке\n",
    "test_heroes = np.unique(X_test[['r1_hero','r2_hero','r3_hero','r4_hero','r5_hero',\n",
    "                                      'd1_hero','d2_hero','d3_hero','d4_hero','d5_hero']].values)\n",
    "#удалим категориальные признаки\n",
    "\n",
    "X_test_cleaned = X_test.drop(labels=['lobby_type','r1_hero','r2_hero','r3_hero','r4_hero','r5_hero',\n",
    "                                      'd1_hero','d2_hero','d3_hero','d4_hero','d5_hero'], axis=1)\n",
    "X_test_cleaned_scaled=scaler.transform(X_test_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#формируем мешок слов по героям\n",
    "# N — количество различных героев в выборке\n",
    "X_pick_test = np.zeros((X_test.shape[0], max(test_heroes)))\n",
    "for i, match_id in enumerate(X_test.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, X_test.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, X_test.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#склеиваем с новым признаком\n",
    "X_dummies_test = np.concatenate([X_test_cleaned_scaled, X_pick_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cчитаем вероятности на обученном классификаторе\n",
    "pre = lgr2.predict_proba(X_dummies_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0060437516906335365\n",
      "0.9943054890808856\n"
     ]
    }
   ],
   "source": [
    "# получаем значения вероятности radiant для того чтобы получить максимальное и минимальное. костыли, да.\n",
    "radiant = [0]*len(pre)\n",
    "for i in range(len(pre)):\n",
    "    radiant[i]=pre[i][0]\n",
    "print(min(radiant))\n",
    "print(max(radiant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отчёт по исследованию логистической регрессии\n",
    "1. Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?\n",
    "\n",
    "0.7179727586106518\n",
    "Логистическая регрессия работает не сильно быстрее быстрее чем градиентный бустинг, хотя и является линейной функцией.\n",
    "\n",
    "2. Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение?\n",
    "\n",
    "0.7178321071588762\n",
    "Качество значительно не изменилось, так как признаков было немного и они являлись шумом, не принося смыслового значения прогнозу.\n",
    "\n",
    "3. Сколько различных идентификаторов героев существует в данной игре?\n",
    "\n",
    "Всего существует 108 разных идентификаторов.\n",
    "Но в коде пришлось использовать маскимальное значение идентификатора - 112 из-за особенностей реализации готовой функции.\n",
    "\n",
    "4. Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить?\n",
    "\n",
    "Да, качество улучшилось - стало ```z0.7544331359955426```, что является сейчас максимальным. Я считаю, что причиной этого служит добавление признаков игрока, так как они влияют на игру, и теперь у нас больше полезных признаков. \n",
    "\n",
    "5. Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?\n",
    "Лучший алгоритм - логистическая регрессия с мешком слов.\n",
    "Минимальное значение: ```0.0060437516906335365```\n",
    "Максимальное значение: ```0.9943054890808856```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-281-bb6d388e8bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# kaggle_df['match_id']=X_test['match_id']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkaggle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'radiant_win'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradiant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# kaggle_df['match_id']=X_test['match_id']\n",
    "# kaggle_df['radiant_win']=df(radiant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
